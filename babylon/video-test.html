<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml">

<!--
Turns on your microphone and plays your sound at the place of loaded character.

This requires locally running OpenVidu. Run it like 
docker run -p 4443:4443 --rm -e OPENVIDU_SECRET=MY_SECRET -e DOMAIN_OR_PUBLIC_IP=YOUR-IP-ADDRESS openvidu/openvidu-server-kms:2.17.0
Mind that YOUR-IP-ADDRESS should not be localhost (127.0.0.1) but your LAN address
 -->
    <head>
      <meta content="text/html;charset=utf-8" http-equiv="Content-Type">
      <meta content="utf-8" http-equiv="encoding">
    <title>VRSpace/Babylon.js</title>
    ﻿<style type="text/css">
    html, body {
      width: 100%;
      height:100%;
      margin: 0px;
      paddin: 0px;
    }
    canvas {
      width: 98%;
      height:96%;
      padding-left: 0;
      padding-right: 0;
      margin-left: auto;
      margin-right: auto;
      display: block;
    }
    </style>﻿
        <script src="https://cdn.babylonjs.com/babylon.js"></script>
        <script src="https://cdn.babylonjs.com/loaders/babylonjs.loaders.min.js"></script>
        <script src="https://code.jquery.com/jquery-3.3.1.min.js" integrity="sha256-FgpCb/KJQlLNfOu91ta32o/NMZxltwRo8QtmkMRdAu8=" crossorigin="anonymous"></script>
        <script src="./js/lib/openvidu-browser-2.17.0.js"></script>
    </head>
  <body>

    <canvas id="renderCanvas" touch-action="none"></canvas>

<script>
var canvas = document.getElementById("renderCanvas"); // Get the canvas element
var engine = new BABYLON.Engine(canvas, true); // Generate the BABYLON 3D engine
var scene;
var voice = null;
var video = null;

import('./video-test.js').then( (ui) => {
  world = new ui.VideoWorld();
  world.init(engine, 'video', world.scene).then((s) => {
    scene = s;
    world.initXR();
  });
  
});

function startStreaming() {
  world.connect('test').then(() => {
    world.media.publish('videos');
    // once we start publishing...
    world.media.publisher.on('streamCreated',  event => {
      // this is much the same as world.media.subscribe(world.mesh);
      // except we're subscribing to publisher here
      console.log("New publisher stream!")
      console.log(event);
      //publisher.publishAudio(true); // automatic
      // now this event.stream.getMediaStream is supposed return MediaStream
      // that can be used as Sound constructor parameter
      // create sound and bind it to the avatar
      voice = new BABYLON.Sound(
        "voice",
        event.stream.getMediaStream(),
        scene, null, {
          loop: false,
          autoplay: true,
          spatialSound: true,
          streaming: true,
          distanceModel: "linear",
          maxDistance: 50, // default 100, used only when linear
          panningModel: "equalpower" // or "HRTF"
        });
      voice.attachToMesh(world.mesh);
      
      video = BABYLON.VideoTexture.CreateFromStreamAsync(scene, event.stream.getMediaStream()).then( (texture) => {
          // TODO attach this texture to the mesh as diffuseTexture
          world.mesh.material.diffuseTexture = texture;
      });
      
    });
    
  });
}

function debugOnOff() {
    console.log("Debug: "+scene.debugLayer.isVisible());
    if ( scene.debugLayer.isVisible() ) {
      scene.debugLayer.hide();
    } else {
      scene.debugLayer.show();
    }
    console.log(BABYLON.Engine.audioEngine.audioContext);
    BABYLON.Engine.audioEngine.audioContext.resume().then(() => {
      console.log('Playback resumed successfully');
    });
  }

  //Watch for browser/canvas resize events
  window.addEventListener("resize", function () {
    engine.resize();
  });

</script>
<div style="position:absolute;bottom:10px;right:50%;">
<button onClick="startStreaming()">Video</button>
<button onClick="debugOnOff()">Debug</button>
</div>
<div id="videos" hidden>
</div>
</body>
</html>
